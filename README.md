# VolcanoLake

Proyecto de Inteligencia Artificial que implementa un agente de Reinforcement Learning basado en Q-Learning con estrategia epsilon-greedy para navegar entornos tipo grid-world.

## ğŸ“‹ DescripciÃ³n

VolcanoLake es un entorno inspirado en FrozenLake de Gymnasium donde el agente debe navegar desde un punto de inicio hasta una meta, evitando peligros (lava, agua) y recolectando recompensas (tesoros) por el camino. El proyecto incluye tres versiones evolutivas que demuestran diferentes enfoques de diseÃ±o y complejidad creciente.

## ğŸ® MecÃ¡nicas del Juego

### Tipos de Casillas
- **S (Start)**: Punto de inicio del agente
- **G (Goal)**: Meta (+10 puntos, termina episodio con Ã©xito)
- **L (Lava)**: Lava (-10 puntos, termina episodio con fracaso)
- **W (Water)**: Agua (-1 punto, causa deslizamiento probabilÃ­stico)
- **T (Treasure)**: Tesoro (+5 puntos, se consume al recogerlo)
- **. (Ground)**: Tierra (-0.001 puntos, neutral)

### Sistema de Deslizamiento (Agua)
Cuando el agente estÃ¡ sobre una casilla de agua ('W'), el movimiento se vuelve probabilÃ­stico:
- **80%**: Movimiento exitoso en la direcciÃ³n deseada
- **10%**: Desliza 90Â° a la izquierda (cardinal) o solo componente vertical (diagonal)
- **10%**: Desliza 90Â° a la derecha (cardinal) o solo componente horizontal (diagonal)

### Acciones Disponibles
El agente puede moverse en 8 direcciones:
- **0-3**: Movimientos cardinales (Arriba, Derecha, Abajo, Izquierda)
- **4-7**: Movimientos diagonales (Arriba-Derecha, Abajo-Derecha, Abajo-Izquierda, Arriba-Izquierda)

## ğŸ“ Estructura del Proyecto

```
VolcanoLake/
â”‚
â”œâ”€â”€ VolcanoLake_v1/              # VersiÃ³n base con FrozenLake estÃ¡ndar
â”‚   â”œâ”€â”€ main.py                  # Script principal de entrenamiento
â”‚   â”œâ”€â”€ agent.py                 # ImplementaciÃ³n del agente Q-Learning
â”‚   â””â”€â”€ utils.py                 # Funciones de visualizaciÃ³n
â”‚
â”œâ”€â”€ VolcanoLake_v2/              # VersiÃ³n mejorada con wrappers
â”‚   â”œâ”€â”€ main.py                  # Script de entrenamiento extendido
â”‚   â”œâ”€â”€ agent.py                 # Agente Q-Learning mejorado
â”‚   â”œâ”€â”€ wrappers.py              # Wrappers personalizados de Gymnasium
â”‚   â””â”€â”€ utils.py                 # Utilidades de grÃ¡ficos
â”‚
â”œâ”€â”€ VolcanoLake_v3/              # Entorno personalizado completo â­
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â””â”€â”€ qlearning_agent.py  # Agente Q-Learning optimizado
â”‚   â”‚
â”‚   â”œâ”€â”€ envs/
â”‚   â”‚   â””â”€â”€ volcano_lake_env.py # Entorno personalizado (Gymnasium API)
â”‚   â”‚
â”‚   â”œâ”€â”€ maps/                    # Mapas de diferentes tamaÃ±os
â”‚   â”‚   â”œâ”€â”€ map_5x5.csv         # Mapa pequeÃ±o (aprendizaje rÃ¡pido)
â”‚   â”‚   â”œâ”€â”€ map_25x25.csv       # Mapa mediano (por defecto)
â”‚   â”‚   â”œâ”€â”€ map_50x50.csv       # Mapa grande (desafÃ­o)
â”‚   â”‚   â””â”€â”€ map_100x100.csv     # Mapa muy grande (exploracion avanzada)
â”‚   â”‚
â”‚   â”œâ”€â”€ plots/                   # GrÃ¡ficas generadas (creadas automÃ¡ticamente)
â”‚   â”‚   â”œâ”€â”€ volcanolake_policy_map.png        # Mapa de polÃ­ticas Ã³ptimas
â”‚   â”‚   â”œâ”€â”€ volcanolake_training_metrics.png  # MÃ©tricas de entrenamiento
â”‚   â”‚   â””â”€â”€ volcanolake_value_heatmap.png     # Mapa de calor de valores Q
â”‚   â”‚
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ generate_maps.py    # Generador automÃ¡tico de mapas CSV
â”‚   â”‚
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ train_agent.py      # LÃ³gica de entrenamiento modular
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ plotting.py         # Funciones de visualizaciÃ³n avanzada
â”‚   â”‚
â”‚   â”œâ”€â”€ videos/                  # Videos de episodios (creados automÃ¡ticamente)
â”‚   â”‚   â””â”€â”€ rl-video-episode-99999.mp4  # Ãšltimo episodio grabado
â”‚   â”‚
â”‚   â”œâ”€â”€ wrappers/
â”‚   â”‚   â””â”€â”€ wrappers.py         # Wrappers adicionales para el entorno
â”‚   â”‚
â”‚   â””â”€â”€ main.py                  # Punto de entrada principal
â”‚
â”œâ”€â”€ requirements.txt             # Dependencias del proyecto
â””â”€â”€ README.md                    # Este archivo
```

## ğŸ”„ Versiones del Proyecto

### VolcanoLake_v1: Base con FrozenLake
**Objetivo**: FamiliarizaciÃ³n con Gymnasium y Q-Learning bÃ¡sico

- **Entorno**: FrozenLake estÃ¡ndar de Gymnasium (4x4)
- **CaracterÃ­sticas**:
  - ImplementaciÃ³n bÃ¡sica de Q-Learning desde cero
  - PolÃ­tica epsilon-greedy simple
  - Con deslizamiento natural (`is_slippery=True`)
  - Entorno predeterminado sin modificaciones
  - MÃ©tricas bÃ¡sicas de rendimiento

**Ideal para**: Entender los fundamentos del aprendizaje por refuerzo

### VolcanoLake_v2: ExtensiÃ³n con Wrappers
**Objetivo**: ExploraciÃ³n de wrappers y modificaciÃ³n dinÃ¡mica del entorno

- **Entorno**: FrozenLake + Wrappers personalizados de Gymnasium
- **CaracterÃ­sticas**:
  - Wrappers de modificaciÃ³n del entorno:
    - `IncreasingHoles`: AÃ±ade agujeros progresivamente durante el entrenamiento
    - `LimitedVision`: Restringe la observaciÃ³n del agente (POMDP)
    - `LimitedVisionRewardShaping`: Moldeado de recompensas con informaciÃ³n parcial
  - GrabaciÃ³n automÃ¡tica de videos del Ãºltimo episodio
  - LÃ­mite de tiempo por episodio (`TimeLimit` wrapper)
  - EstadÃ­sticas de entrenamiento extendidas
  - VisualizaciÃ³n mejorada de mÃ©tricas

**Ideal para**: Entender cÃ³mo modificar entornos existentes y aplicar transfer learning

### VolcanoLake_v3: Entorno Personalizado â­
**Objetivo**: ImplementaciÃ³n completa de un entorno custom siguiendo Gymnasium API

- **Entorno**: VolcanoLake completamente personalizado
- **CaracterÃ­sticas principales**:
  - **Entorno propio** con 6 tipos de casillas diferentes
  - **Mapas escalables** vÃ­a CSV (5x5 hasta 100x100)
  - **8 direcciones de movimiento** (cardinal + diagonal)
  - **Sistema probabilÃ­stico** de deslizamiento en agua
  - **Tesoros dinÃ¡micos** que se consumen durante el episodio
  - **Renderizado avanzado** con Pygame (modos `human` y `rgb_array`)
  - **Tracking completo**:
    - Tesoros recolectados por episodio
    - Tasa de Ã©xito/fracaso
    - Longitud de episodios
    - Error TD durante entrenamiento
  - **Clipping de bordes**: El agente no puede salir del mapa
  - **Arquitectura modular** con separaciÃ³n clara de responsabilidades
  - **Generador de mapas** para crear escenarios personalizados

**Ideal para**: Proyectos avanzados y research en RL custom environments

## ğŸš€ InstalaciÃ³n

### Requisitos Previos
- Python 3.8 o superior
- pip (gestor de paquetes de Python)

### Pasos de InstalaciÃ³n

1. **Clonar el repositorio**:
   ```bash
   git clone https://github.com/tu-usuario/VolcanoLake.git
   cd VolcanoLake
   ```

2. **Crear entorno virtual** (recomendado):
   ```bash
   python -m venv venv
   
   # En Windows:
   venv\Scripts\activate
   
   # En Linux/Mac:
   source venv/bin/activate
   ```

3. **Instalar dependencias**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Verificar instalaciÃ³n**:
   ```bash
   python -c "import gymnasium; print('Gymnasium OK')"
   ```

## ğŸ¯ Uso

### Ejecutar VolcanoLake_v1
```bash
cd VolcanoLake_v1
python main.py
```

### Ejecutar VolcanoLake_v2
```bash
cd VolcanoLake_v2
python main.py
```

### Ejecutar VolcanoLake_v3
```bash
cd VolcanoLake_v3
python main.py
```

### ParÃ¡metros Configurables

Todas las versiones comparten la misma estructura de configuraciÃ³n del agente Q-Learning. Los parÃ¡metros principales se encuentran en el archivo `main.py` (v1, v2) o `training/train_agent.py` (v3):

#### HiperparÃ¡metros del Agente Q-Learning

```python
# NÃºmero de episodios de entrenamiento
n_episodes = 100_000

# HiperparÃ¡metros del agente
learning_rate = 0.01          # Tasa de aprendizaje (Î±): controla cuÃ¡nto aprende en cada paso
discount_factor = 0.99        # Factor de descuento (Î³): importancia del futuro vs presente
start_epsilon = 1.0           # Epsilon inicial: 100% exploraciÃ³n al inicio
final_epsilon = 0.1           # Epsilon final: 10% exploraciÃ³n al final
epsilon_decay = start_epsilon / (n_episodes / 2)  # Decaimiento lineal

# VisualizaciÃ³n
plot_save = True              # True: guardar en plots/, False: mostrar en pantalla
render_mode = "rgb_array"     # 'human' (ventana), 'rgb_array' (video), None (sin render)
```

#### ConfiguraciÃ³n de Wrappers

Los wrappers permiten modificar el comportamiento del entorno sin cambiar su cÃ³digo base. Puedes activar/desactivar los que necesites comentando/descomentando las lÃ­neas correspondientes.

##### âš ï¸ Reglas Importantes:
1. **El orden importa**: Los wrappers se aplican de arriba hacia abajo
2. **RecordEpisodeStatistics** debe ir SIEMPRE al final
3. Wrappers de modificaciÃ³n del entorno van primero, estadÃ­sticas al final

---

##### VersiÃ³n 2 (v2) - Archivo: `main.py`

```python
# Crear entorno base
env = gym.make("FrozenLake-v1", is_slippery=False, render_mode="rgb_array")

# --- WRAPPERS OPCIONALES (comentar/descomentar segÃºn necesites) ---

# 1ï¸âƒ£ IncreasingHoles: AÃ±ade agujeros progresivamente durante entrenamiento
env = IncreasingHoles(env, max_holes=2, hole_increase_rate=0.0001)

# 2ï¸âƒ£ LimitedVisionRewardShaping: VisiÃ³n limitada + seÃ±ales de recompensa
#    El agente solo ve la casilla de la derecha
# env = LimitedVisionRewardShaping(env)

# 3ï¸âƒ£ LimitedVision: VisiÃ³n limitada segÃºn direcciÃ³n del movimiento
#    El agente ve solo hacia donde se moviÃ³ (POMDP)
# env = LimitedVision(env)

# 4ï¸âƒ£ TimeLimit: LÃ­mite de pasos por episodio (evita loops infinitos)
env = gym.wrappers.TimeLimit(env, max_episode_steps=20)

# 5ï¸âƒ£ RecordVideo: Graba el Ãºltimo episodio
video_folder = os.path.join(os.path.dirname(__file__), "videos")
os.makedirs(video_folder, exist_ok=True)
env = gym.wrappers.RecordVideo(
    env, 
    video_folder=video_folder,
    episode_trigger=lambda ep: ep == n_episodes - 1
)

# 6ï¸âƒ£ RecordEpisodeStatistics: SIEMPRE AL FINAL
env = gym.wrappers.RecordEpisodeStatistics(env, buffer_length=n_episodes)
```

---

##### VersiÃ³n 3 (v3) - Archivo: `training/train_agent.py`

```python
# ConfiguraciÃ³n del mapa
map_file_path = 'maps/map_25x25.csv'  # Opciones: map_5x5, map_25x25, map_50x50, map_100x100

# Crear entorno personalizado
env = VolcanoLakeEnv(map_file_path=map_file_path, render_mode=render_mode)

# --- WRAPPERS OPCIONALES (comentar/descomentar segÃºn necesites) ---

# 1ï¸âƒ£ IncreasingHoles: AÃ±ade lava dinÃ¡micamente (requiere adaptaciÃ³n)
# from wrappers.wrappers import IncreasingHoles
# env = IncreasingHoles(env, max_holes=5, hole_increase_rate=0.0001)

# 2ï¸âƒ£ LimitedVision: ObservaciÃ³n parcial del entorno (POMDP)
# from wrappers.wrappers import LimitedVision
# env = LimitedVision(env)

# 3ï¸âƒ£ LimitedVisionRewardShaping: VisiÃ³n limitada + guÃ­a con recompensas
# from wrappers.wrappers import LimitedVisionRewardShaping
# env = LimitedVisionRewardShaping(env)

# 4ï¸âƒ£ TimeLimit: LÃ­mite de pasos (ajustar segÃºn tamaÃ±o del mapa)
env = gym.wrappers.TimeLimit(env, max_episode_steps=100)

# 5ï¸âƒ£ RecordVideo: Graba episodios clave
video_folder = os.path.join(os.path.dirname(__file__), "..", "videos")
os.makedirs(video_folder, exist_ok=True)
env = gym.wrappers.RecordVideo(
    env,
    video_folder=video_folder,
    episode_trigger=lambda ep: ep % 10000 == 0 or ep == n_episodes - 1
)

# 6ï¸âƒ£ RecordEpisodeStatistics: SIEMPRE AL FINAL
env = gym.wrappers.RecordEpisodeStatistics(env, buffer_length=n_episodes)
```

---

#### GuÃ­a RÃ¡pida de Wrappers

| Wrapper | QuÃ© hace | CuÃ¡ndo usar |
|---------|----------|-------------|
| **IncreasingHoles** | AÃ±ade obstÃ¡culos progresivamente | Curriculum learning, aumentar dificultad |
| **LimitedVision** | Restringe observaciÃ³n del agente | InvestigaciÃ³n POMDP, visiÃ³n parcial |
| **LimitedVisionRewardShaping** | VisiÃ³n limitada + recompensas guÃ­a | POMDP + ayuda al aprendizaje |
| **TimeLimit** | LÃ­mite mÃ¡ximo de pasos | Siempre (evita loops infinitos) |
| **RecordVideo** | Graba episodios | AnÃ¡lisis visual, demos |
| **RecordEpisodeStatistics** | MÃ©tricas de rendimiento | Siempre (anÃ¡lisis de entrenamiento) |

## ğŸ“Š Algoritmo Q-Learning

### EcuaciÃ³n de ActualizaciÃ³n (Bellman)
```
Q(s,a) â† Q(s,a) + Î±[r + Î³ max Q(s',a') - Q(s,a)]
                      ï¸¸____________ï¸¸
                         TD Error
```

**Componentes**:
- **s**: Estado actual del agente
- **a**: AcciÃ³n ejecutada
- **r**: Recompensa inmediata obtenida
- **s'**: Estado siguiente (despuÃ©s de ejecutar la acciÃ³n)
- **Î±** (alpha): Learning rate - controla cuÃ¡nto actualizamos (0-1)
- **Î³** (gamma): Discount factor - importancia del futuro vs presente (0-1)

### PolÃ­tica Epsilon-Greedy

Balance dinÃ¡mico entre **exploraciÃ³n** (descubrir) y **explotaciÃ³n** (aprovechar):

```python
if random() < epsilon:
    acciÃ³n = acciÃ³n_aleatoria()      # EXPLORACIÃ“N: Probar cosas nuevas
else:
    acciÃ³n = argmax(Q[estado])       # EXPLOTACIÃ“N: Usar lo aprendido
    
# epsilon decrece con el tiempo: 1.0 â†’ 0.1
# MÃ¡s exploraciÃ³n al inicio, mÃ¡s explotaciÃ³n al final
```

## ğŸ“ˆ MÃ©tricas de Entrenamiento

El sistema genera automÃ¡ticamente grÃ¡ficas con tres mÃ©tricas clave:

### 1. Recompensas Acumuladas por Episodio
- **QuÃ© muestra**: Suma total de recompensas obtenidas en cada episodio
- **Objetivo**: Curva ascendente indica aprendizaje exitoso
- **Suavizado**: Media mÃ³vil de 500 episodios para reducir ruido

### 2. DuraciÃ³n de Episodios
- **QuÃ© muestra**: NÃºmero de pasos hasta terminar cada episodio
- **Objetivo**: DuraciÃ³n estable indica convergencia de la polÃ­tica
- **InterpretaciÃ³n**: 
  - Muy corto â†’ Muerte prematura (mala polÃ­tica)
  - Muy largo â†’ Deambular sin propÃ³sito
  - Ã“ptimo â†’ Ruta eficiente hacia la meta

### 3. Error TD (Temporal Difference)
- **QuÃ© muestra**: Magnitud de las actualizaciones en la Q-table
- **Objetivo**: Error decreciente indica convergencia
- **FÃ³rmula**: `|r + Î³ max Q(s',a') - Q(s,a)|`

**UbicaciÃ³n de las grÃ¡ficas**: 
- v1/v2: Se muestran en pantalla o se guardan en raÃ­z
- v3: Carpeta `plots/` dentro de VolcanoLake_v3

## ğŸ› ï¸ TecnologÃ­as Utilizadas

| LibrerÃ­a | VersiÃ³n | PropÃ³sito |
|----------|---------|-----------|
| **Gymnasium** | 1.2.1 | Framework de entornos de RL (sucesor de OpenAI Gym) |
| **NumPy** | 2.3.4 | Operaciones numÃ©ricas y manejo de arrays |
| **Matplotlib** | 3.10.7 | VisualizaciÃ³n de mÃ©tricas y grÃ¡ficas |
| **Pygame** | 2.6.1 | Renderizado grÃ¡fico 2D del entorno |
| **tqdm** | 4.67.1 | Barras de progreso para el entrenamiento |

## ğŸ“ Crear Mapas Personalizados (v3)

### Usando el Generador AutomÃ¡tico

```bash
cd VolcanoLake_v3/scripts
python generate_maps.py
```

Esto crearÃ¡ 4 mapas predefinidos en la carpeta `maps/`:
- `map_5x5.csv` (25 casillas)
- `map_25x25.csv` (625 casillas)
- `map_50x50.csv` (2,500 casillas)
- `map_100x100.csv` (10,000 casillas)

### CreaciÃ³n Manual

Crea un archivo CSV con la estructura:

```csv
S,.,.,W,L
.,L,.,W,.
T,.,W,.,L
.,L,.,.,T
.,.,L,W,G
```

**Reglas**:
- Debe haber exactamente **1 casilla 'S'** (inicio)
- Debe haber exactamente **1 casilla 'G'** (meta)
- Puedes aÃ±adir mÃºltiples 'L' (lava), 'W' (agua), 'T' (tesoros)
- Las casillas '.' representan terreno neutral

**Cargar en el cÃ³digo**:

```python
from envs.volcano_lake_env import VolcanoLakeEnv

env = VolcanoLakeEnv(
    map_file_path='maps/tu_mapa_custom.csv', 
    render_mode='human'
)
```

## ğŸ“ Contexto AcadÃ©mico

**Asignatura**: Inteligencia Artificial  
**Nivel**: Tercer aÃ±o de IngenierÃ­a InformÃ¡tica  
**Universidad**: CUNEF Universidad  
**AÃ±o acadÃ©mico**: 2025-2026

### Objetivos de Aprendizaje

Este proyecto demuestra:
1. âœ… ImplementaciÃ³n prÃ¡ctica de algoritmos de **Reinforcement Learning**
2. âœ… DiseÃ±o de **entornos personalizados** siguiendo Gymnasium API
3. âœ… AplicaciÃ³n de **wrappers** para modificar entornos existentes
4. âœ… VisualizaciÃ³n y anÃ¡lisis de **mÃ©tricas de aprendizaje**
5. âœ… Desarrollo de cÃ³digo modular y bien documentado
6. âœ… IntegraciÃ³n de mÃºltiples librerÃ­as de Python cientÃ­fico

### Competencias Desarrolladas
- DiseÃ±o de sistemas de IA
- ProgramaciÃ³n orientada a objetos
- AnÃ¡lisis de algoritmos de aprendizaje
- DocumentaciÃ³n tÃ©cnica
- Control de versiones con Git

## ğŸ‘¥ Autores

- **Eduardo EstefanÃ­a Ovejero** - IngenierÃ­a InformÃ¡tica, CUNEF Universidad
- **Ãlvaro MartÃ­n GarcÃ­a** - IngenierÃ­a InformÃ¡tica, CUNEF Universidad

---

<div align="center">

**VolcanoLake**

*Proyecto acadÃ©mico - CUNEF Universidad - 2025-2026*

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Gymnasium](https://img.shields.io/badge/Gymnasium-1.2.1-green.svg)](https://gymnasium.farama.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

</div>